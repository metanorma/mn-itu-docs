[[sec-1]]
== Introduction

Digital technologies and artificial intelligence (AI), particularly machine learning,
are transforming medicine, medical research and public health. Technologies based on
AI are now used in health services in countries of the Organization for Economic
Co-operation and Development (OECD), and its utility is being assessed in low- and
middle-income countries (LMIC). The United Nations Secretary-General has stated that
safe deployment of new technologies, including AI, can help the world to achieve the
United Nations Sustainable Development Goals <<sdg-report>>, which would include the
health-related objectives under Sustainable Development Goal 3. AI could also help to
meet global commitments to achieve universal health coverage.

Use of AI for health nevertheless raises trans-national ethical, legal, commercial
and social concerns. Many of these concerns are not unique to AI. The use of software
and computing in health care has challenged developers, governments and providers for
half a century, and AI poses additional, novel ethical challenges that extend beyond
the purview of traditional regulators and participants in health-care systems. These
ethical challenges must be adequately addressed if AI is to be widely used to improve
human health, to preserve human autonomy and to ensure equitable access to such
technologies.

Use of AI technologies for health holds great promise and has already contributed to
important advances in fields such as drug discovery, genomics, radiology, pathology
and prevention. AI could assist health-care providers in avoiding errors and allow
clinicians to focus on providing care and solving complex cases. The potential
benefits of these technologies and the economic and commercial potential of AI for
health care presage ever greater use of AI worldwide.

Unchecked optimism in the potential benefits of AI could, however, veer towards
habitual first recourse to technological solutions to complex problems. Such
"techno-optimism" could make matters worse, for example, by exacerbating the unequal
distribution of access to health-care technologies within and among wealthy and
low-income countries <<timmermans>>. Furthermore, the digital divide could exacerbate
inequitable access to health-care technologies by geography, gender, age or
availability of devices, if countries do not take appropriate measures. Inappropriate
use of AI could also perpetuate or exacerbate bias. Use of limited, low-quality,
non-representative data in AI could perpetuate and deepen prejudices and disparities
in health care. Biased inferences, misleading data analyses and poorly designed
health applications and tools could be harmful. Predictive algorithms based on
inadequate or inappropriate data can result in significant racial or ethnic bias. Use
of high-quality, comprehensive datasets is essential.

AI could present a singular opportunity to augment and improve the capabilities of
over-stretched health-care workers and providers. Yet, the introduction of AI for
health care, as in many other sectors of the global economy, could have a significant
negative impact on the health-care workforce. It could reduce the size of the
workforce, limit, challenge or degrade the skills of health workers, and oblige them
to retrain to adapt to the use of AI. Centuries of medical practice are based on
relationships between provider and patient, and particular care must be taken when
introducing AI technologies so that they do not disrupt such relationships.

The Universal Declaration of Human Rights, which includes pillars of patient rights
such as dignity, privacy, confidentiality and informed consent, might be dramatically
redefined or undermined as digital technologies take hold and expand. The performance
of AI depends (among other factors) on the nature, type and volume of data and
associated information and the conditions under which such data were gathered. The
pursuit of data, whether by government or companies, could undermine privacy and
autonomy at the service of government or private surveillance or commercial profit.
If privacy and autonomy are not assured, the resulting limitation of the ability to
exercise the full range of human rights, including civil and political rights (such
as freedom of movement and expression) and social and economic rights (such as access
to health care and education), might have a wider impact.

AI technologies, like many information technologies used in health care, are usually
designed by companies or through public-private partnerships (PPPs), although many
governments also develop and deploy these technologies. Some of the world's largest
technology companies are developing new applications and services, which they either
own or invest in. Many of these companies have already accumulated large quantities
of data, including health data, and exercise significant power in society and the
economy. While these companies may offer innovative approaches, there is concern that
they might eventually exercise too much power in relation to governments, providers
and patients.

AI technologies are also changing where people access health care. AI technologies
for health are increasingly distributed outside regulated health-care settings,
including at the workplace, on social media and in the education system. With the
rapid proliferation and evolving uses of AI for health care, including in response to
the COVID-19 pandemic, government agencies, academic institutions, foundations,
nongovernmental organizations and national ethics committees are defining how
governments and other entities should use and regulate such technologies effectively.
Ethically optimized tools and applications could sustain widespread use of AI to
improve human health and the quality of life, while mitigating or eliminating many
risks and bad practices.

To date, there is no comprehensive international guidance on use of AI for health in
accordance with ethical norms and human rights standards. Most countries do not have
laws or regulations to regulate use of AI technologies for health care, and their
existing laws may not be adequate or specific enough for this purpose. WHO recognizes
that ethics guidance based on the shared perspectives of the different entities that
develop, use or oversee such technologies is critical to build trust in these
technologies, to guard against negative or erosive effects and to avoid the
proliferation of contradictory guidelines. Harmonized ethics guidance is therefore
essential for the design and implementation of AI for global health.

The primary readership of this guidance document is ministries of health, as it is
they that determine how to introduce, integrate and harness these technologies for
the public good while restricting or prohibiting inappropriate use. The development,
adoption and use of AI nevertheless requires an integrated, coordinated approach
among government ministries beyond that for health. The stakeholders also include
regulatory agencies, which must validate and define whether, when and how such
technologies are to be used, ministries of education that teach current and future
health-care workforces how such technologies function and are to be integrated into
everyday practice, ministries of information technology that should facilitate the
appropriate collection and use of health data and narrow the digital divide and
countries' legal systems that should ensure that people harmed by AI technologies can
seek redress.

This guidance document is also intended for the stakeholders throughout the
health-care system who will have to adapt to and adopt these technologies, including
medical researchers, scientists, health-care workers and, especially, patients.
Access to such technologies can empower people who fall ill but can also leave them
vulnerable, with fewer services and less protection. People have always been at the
centre at all levels of decision-making in health care, whereas the inevitable growth
of AI for health care could eventually challenge human primacy over medicine and
health.

This guidance is also designed for those responsible for the design, deployment and
refinement of AI technologies, including technologists and software developers.
Finally, it is intended to guide the companies, universities, medical associations
and international organizations that will, with governments and ministries of health,
set policies and practices to define use of AI in the health sector. In identifying
the many ethical concerns raised by AI and by providing the relevant ethical
frameworks to address such concerns, this document is intended to support responsible
use of AI worldwide.

AI is a fast-moving, evolving field and that many applications, not yet envisaged,
will emerge as ever-greater public and private investment is dedicated to the use of
AI for health. For example, in 2020, WHO issued interim guidance on the
https://apps.who.int/iris/handle/10665/332200[use of proximity tracking applications]
intended to facilitate contact-tracing during the COVID-19 pandemic. WHO may consider
specific guidance for additional tools and applications and periodically update this
guidance to keep pace with this rapidly changing field.
